{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
      "  Downloading langchain_core-0.3.35-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Downloading numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain-openai) (1.58.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "Downloading langchain_core-0.3.35-py3-none-any.whl (413 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Downloading numpy-2.2.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/12.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.6 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 894.9/894.9 kB 6.7 MB/s eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: zstandard, orjson, numpy, jsonpointer, tiktoken, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.18 langchain-core-0.3.35 langchain-openai-0.3.6 langchain-text-splitters-0.3.6 langsmith-0.3.8 numpy-2.2.3 orjson-3.10.15 requests-toolbelt-1.0.0 tiktoken-0.9.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T15:16:09.234109Z",
     "start_time": "2025-08-16T15:16:08.758944Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model = ChatOpenAI(model=os.getenv(\"DEFAULT_MODEL\"))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T15:16:21.836912Z",
     "start_time": "2025-08-16T15:16:10.364185Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"안녕? 나는 송정헌이야.\")])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='만나서 반가워요, 송정헌님! 오늘 어떤 일이 있으신가요? 도와드릴 수 있는 게 있다면 편하게 말씀해 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 19, 'total_tokens': 55, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'accounts/fireworks/models/llama4-maverick-instruct-basic', 'system_fingerprint': None, 'id': 'eabdd03c-3160-4262-8371-ae7fb9829811', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c6367192-4ce9-49ac-9fbd-34027a08b99a-0', usage_metadata={'input_tokens': 19, 'output_tokens': 36, 'total_tokens': 55, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T04:11:10.327713Z",
     "start_time": "2025-08-11T04:11:08.765483Z"
    }
   },
   "source": [
    "model.invoke([HumanMessage(content=\"내 이름이 뭐지?\")])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='당신의 이름을 모르거나, 이전에 대화에서 그 정보를 공유하지 않으셨기 때문에, 저는 당신의 이름이 무엇인지 알지 못합니다. 필요하시다면 이름을 알려주시겠어요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 16, 'total_tokens': 57, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'accounts/fireworks/models/llama4-maverick-instruct-basic', 'system_fingerprint': None, 'id': '8fd2aa70-d416-49c7-882d-48d930f5c537', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--65eb0db1-08a9-4f0a-b683-32beffb8da99-0', usage_metadata={'input_tokens': 16, 'output_tokens': 41, 'total_tokens': 57, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T15:18:30.739073Z",
     "start_time": "2025-08-16T15:18:03.609174Z"
    }
   },
   "cell_type": "code",
   "source": "response = model.invoke([HumanMessage(content=\"pydantic 라이브러리 설명 해줘\")])",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T15:22:44.256056Z",
     "start_time": "2025-08-16T15:22:44.253307Z"
    }
   },
   "cell_type": "code",
   "source": "response",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Pydantic은 파이썬에서 데이터 유효성 검사 및 설정을 관리하기 위한 라이브러리입니다. 런타임에 데이터의 타입을 검사하고, 잘못된 데이터가 들어올 경우 에러를 발생시켜 줍니다. 데이터 모델을 정의할 때 파이썬의 타입 힌트를 사용하여 모델을 만들고, 이 모델을 기반으로 데이터의 유효성을 검사합니다.\\n\\n### 주요 특징\\n\\n1. **타입 힌팅을 사용한 데이터 모델 정의**: 파이썬의 타입 힌팅을 사용하여 데이터 모델을 정의할 수 있습니다. 이를 통해 코드의 가독성이 높아지고, IDE나 타입 체커와의 호환성이 좋아집니다.\\n\\n2. **데이터 유효성 검사**: 모델에 정의된 타입과 구조에 따라 데이터의 유효성을 검사합니다. 예를 들어, 정수형 필드에 문자열이 들어오는 경우 에러를 발생시킵니다.\\n\\n3. **중첩된 모델 및 복잡한 데이터 구조 지원**: Pydantic은 중첩된 모델이나 리스트, 딕셔너리와 같은 복잡한 데이터 구조도 지원합니다.\\n\\n4. **커스텀 유효성 검사**: 사용자가 유효성 검사 로직을 커스텀할 수 있는 방법을 제공합니다. 예를 들어, `@validator` 데코레이터를 사용하여 특정 필드에 대한 추가적인 유효성 검사를 구현할 수 있습니다.\\n\\n5. **자동 생성 JSON 스키마**: Pydantic 모델로부터 자동으로 JSON 스키마를 생성할 수 있습니다. 이는 API 문서화 등에 유용하게 사용될 수 있습니다.\\n\\n6. **설정 관리**: 환경 변수나 `.env` 파일 등을 통해 설정을 관리할 때 유용합니다. Pydantic의 `BaseSettings` 클래스를 사용하여 설정값을 로드하고 관리할 수 있습니다.\\n\\n### 예시\\n\\n```python\\nfrom pydantic import BaseModel\\nfrom datetime import date\\nfrom typing import List\\n\\nclass User(BaseModel):\\n    id: int\\n    name: str = 'John Doe'\\n    signup_date: date = None\\n    friends: List[int] = []\\n\\n# 올바른 데이터\\nuser_data = {'id': 123, 'name': 'Jane Doe', 'signup_date': '2022-12-22', 'friends': [1, 2, 3]}\\nuser = User(**user_data)\\nprint(user)\\n\\n# 잘못된 데이터 (예: id가 정수형이 아님)\\ntry:\\n    user_data = {'id': '123', 'name': 'Jane Doe'}\\n    user = User(**user_data)\\nexcept Exception as e:\\n    print(e)\\n```\\n\\n이 예시에서는 `User`라는 데이터 모델을 정의하고, 다양한 타입의 필드를 가진 데이터를 어떻게 다루는지 보여줍니다. Pydantic은 `id` 필드에 정수가 아닌 값이 들어오면 에러를 발생시킵니다.\\n\\nPydantic은 FastAPI와 같은 현대적인 파이썬 웹 프레임워크와 함께 사용될 때 특히 유용하며, 데이터의 유효성을 보장하고 코드의 가독성과 유지보수성을 향상시키는 데 도움이 됩니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 622, 'prompt_tokens': 18, 'total_tokens': 640, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'accounts/fireworks/models/llama4-maverick-instruct-basic', 'system_fingerprint': None, 'id': '7b15ef73-fabb-4011-ad35-18a42e3fe5bf', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--8a7690d8-b9b4-46b0-878c-7b9f93796802-0', usage_metadata={'input_tokens': 18, 'output_tokens': 622, 'total_tokens': 640, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T15:25:39.892608Z",
     "start_time": "2025-08-16T15:25:39.890463Z"
    }
   },
   "cell_type": "code",
   "source": "response.__repr__()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIMessage(content=\"Pydantic은 파이썬에서 데이터 유효성 검사 및 설정을 관리하기 위한 라이브러리입니다. 런타임에 데이터의 타입을 검사하고, 잘못된 데이터가 들어올 경우 에러를 발생시켜 줍니다. 데이터 모델을 정의할 때 파이썬의 타입 힌트를 사용하여 모델을 만들고, 이 모델을 기반으로 데이터의 유효성을 검사합니다.\\\\n\\\\n### 주요 특징\\\\n\\\\n1. **타입 힌팅을 사용한 데이터 모델 정의**: 파이썬의 타입 힌팅을 사용하여 데이터 모델을 정의할 수 있습니다. 이를 통해 코드의 가독성이 높아지고, IDE나 타입 체커와의 호환성이 좋아집니다.\\\\n\\\\n2. **데이터 유효성 검사**: 모델에 정의된 타입과 구조에 따라 데이터의 유효성을 검사합니다. 예를 들어, 정수형 필드에 문자열이 들어오는 경우 에러를 발생시킵니다.\\\\n\\\\n3. **중첩된 모델 및 복잡한 데이터 구조 지원**: Pydantic은 중첩된 모델이나 리스트, 딕셔너리와 같은 복잡한 데이터 구조도 지원합니다.\\\\n\\\\n4. **커스텀 유효성 검사**: 사용자가 유효성 검사 로직을 커스텀할 수 있는 방법을 제공합니다. 예를 들어, `@validator` 데코레이터를 사용하여 특정 필드에 대한 추가적인 유효성 검사를 구현할 수 있습니다.\\\\n\\\\n5. **자동 생성 JSON 스키마**: Pydantic 모델로부터 자동으로 JSON 스키마를 생성할 수 있습니다. 이는 API 문서화 등에 유용하게 사용될 수 있습니다.\\\\n\\\\n6. **설정 관리**: 환경 변수나 `.env` 파일 등을 통해 설정을 관리할 때 유용합니다. Pydantic의 `BaseSettings` 클래스를 사용하여 설정값을 로드하고 관리할 수 있습니다.\\\\n\\\\n### 예시\\\\n\\\\n```python\\\\nfrom pydantic import BaseModel\\\\nfrom datetime import date\\\\nfrom typing import List\\\\n\\\\nclass User(BaseModel):\\\\n    id: int\\\\n    name: str = \\'John Doe\\'\\\\n    signup_date: date = None\\\\n    friends: List[int] = []\\\\n\\\\n# 올바른 데이터\\\\nuser_data = {\\'id\\': 123, \\'name\\': \\'Jane Doe\\', \\'signup_date\\': \\'2022-12-22\\', \\'friends\\': [1, 2, 3]}\\\\nuser = User(**user_data)\\\\nprint(user)\\\\n\\\\n# 잘못된 데이터 (예: id가 정수형이 아님)\\\\ntry:\\\\n    user_data = {\\'id\\': \\'123\\', \\'name\\': \\'Jane Doe\\'}\\\\n    user = User(**user_data)\\\\nexcept Exception as e:\\\\n    print(e)\\\\n```\\\\n\\\\n이 예시에서는 `User`라는 데이터 모델을 정의하고, 다양한 타입의 필드를 가진 데이터를 어떻게 다루는지 보여줍니다. Pydantic은 `id` 필드에 정수가 아닌 값이 들어오면 에러를 발생시킵니다.\\\\n\\\\nPydantic은 FastAPI와 같은 현대적인 파이썬 웹 프레임워크와 함께 사용될 때 특히 유용하며, 데이터의 유효성을 보장하고 코드의 가독성과 유지보수성을 향상시키는 데 도움이 됩니다.\", additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 622, \\'prompt_tokens\\': 18, \\'total_tokens\\': 640, \\'completion_tokens_details\\': None, \\'prompt_tokens_details\\': None}, \\'model_name\\': \\'accounts/fireworks/models/llama4-maverick-instruct-basic\\', \\'system_fingerprint\\': None, \\'id\\': \\'7b15ef73-fabb-4011-ad35-18a42e3fe5bf\\', \\'service_tier\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run--8a7690d8-b9b4-46b0-878c-7b9f93796802-0\\', usage_metadata={\\'input_tokens\\': 18, \\'output_tokens\\': 622, \\'total_tokens\\': 640, \\'input_token_details\\': {}, \\'output_token_details\\': {}})'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
